{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoke Detection Model\n",
    "\n",
    "**Author:** Parker Addison  \n",
    "**Date:** 2022-September – 2022-December"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a model based on either VGG or ResNet to perform binary classification for the presence of smoke in a single image. This model will be instantiated with pre-trained weights on ImageNet, with the final layer replaced with a fully-connected binary-output layer. All weights are unfrozen and the model is trained on a set of imagery for real wildfire locations with a validation set of additional real locations.\n",
    "\n",
    "Finally, we'll evaluate the performance of our model against a holdout dataset of a real location that was not included in the training nor validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import src.data\n",
    "import src.models\n",
    "import src.utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Real Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from: data/EXAMPLE/transformed/train\n",
      "\tClass balance: 66.1% smoke (366 total images)\n",
      "Loaded from: data/EXAMPLE/transformed/valid\n",
      "\tClass balance: 48.5% smoke (297 total images)\n",
      "Loaded from: data/EXAMPLE/transformed/holdout\n",
      "\tClass balance: 50.1% smoke (523 total images)\n",
      "Loaded from: data/EXAMPLE/transformed/virtual\n",
      "\tClass balance: 50.0% smoke (648 total images)\n"
     ]
    }
   ],
   "source": [
    "source = 'data/EXAMPLE/transformed/'\n",
    "batch_size = 64\n",
    "train_loader = src.data.load_tensors_from_folder(Path(source, 'train'), batch_size=batch_size)\n",
    "valid_loader = src.data.load_tensors_from_folder(Path(source, 'valid'), batch_size=batch_size)\n",
    "holdout_loader = src.data.load_tensors_from_folder(Path(source, 'holdout'), batch_size=batch_size)\n",
    "virtual_loader = src.data.load_tensors_from_folder(Path(source, 'virtual'), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = 'vgg16'\n",
    "backbone = 'resnet18'\n",
    "# backbone = 'resnet34'\n",
    "model, device, criterion, optimizer = src.models.initialize_model(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6/6 [01:16<00:00, 12.69s/batch, train_loss=0.202, loss=0.709, acc=0.589, auc=0.585, f1=0.512, prec=0.604, rec=0.444]\n"
     ]
    }
   ],
   "source": [
    "src.models.train(model, train_loader, valid_loader, criterion, optimizer, epochs=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout\n",
      "loss: 0.706\tacc: 0.509\tauc: 0.508\tf1: 0.539\tprec: 0.508\trec: 0.573\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against the real holdout set\n",
    "print('Holdout')\n",
    "src.models.evaluate(model, holdout_loader, criterion, log=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training With Virtual Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = 'vgg16'\n",
    "backbone = 'resnet18'\n",
    "# backbone = 'resnet34'\n",
    "model_virt, device, criterion, optimizer = src.models.initialize_model(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.models.train(model_virt, virtual_loader, valid_loader, criterion, optimizer, epochs=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate against the real holdout set\n",
    "src.models.evaluate(model_virt, valid_loader, criterion, log=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Combined Real + Virtual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = 'vgg16'\n",
    "backbone = 'resnet18'\n",
    "# backbone = 'resnet34'\n",
    "model_comb, device, criterion, optimizer = src.models.initialize_model(backbone)\n",
    "combined_loader = src.data.combine([train_loader.dataset, virtual_loader.dataset], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.models.train(model_comb, combined_loader, valid_loader, criterion, optimizer, epochs=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.models.evaluate(model_comb, holdout_loader, criterion, log=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
